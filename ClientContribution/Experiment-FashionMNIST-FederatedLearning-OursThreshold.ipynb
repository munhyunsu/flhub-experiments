{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369fbb6-5a2a-4d39-9245-8ce8fa3e01fe",
   "metadata": {},
   "source": [
    "# Experiment with Fashion MNIST\n",
    "## Federated learning with ours threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7467f-3d63-40c4-b7ce-d6f024368afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['AUTHGRAPH_VERBOSITY'] = '0'\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.random.set_seed(6292)\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344922b-d8b2-4c05-8011-1996c2a97843",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab19e80-bf38-4a0f-b0cf-f7d8726836fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e06f6-1e6f-4da4-9779-d575da9748c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnames = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d43fe-f100-4f08-9855-4eb820a945c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.abspath(os.path.expanduser('dataset-fashionmnist'))\n",
    "dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8469c9-21e1-478e-aed2-1269b2ecc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.abspath(os.path.expanduser(f'model-fashionmnist-oursthreshold-{today}'))\n",
    "model_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30770e-4f89-4353-beba-128763cde314",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = pd.read_csv('round-fashionmnist.csv', index_col='Clients')\n",
    "found.fillna(-1, inplace=True)\n",
    "found = found.astype('int')\n",
    "found.drop(columns=['Total'], inplace=True)\n",
    "found.drop(index=['Total'], inplace=True)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351a07b-9bca-4535-83b7-39154f62e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_round = np.unique(found.values).tolist()\n",
    "found_round.remove(-1)\n",
    "found_round.sort(reverse=False)\n",
    "found_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2a7fc-047c-4a5f-95f1-992e59eeca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_label = dict()\n",
    "for fr in found_round:\n",
    "    label = found_label.get('all', dict())\n",
    "    label[fr] = found.columns[((-1 < found.loc[:, :]) & \n",
    "                               (found.loc[:, :] <= fr)).any()].tolist()\n",
    "    found_label['all'] = label\n",
    "    for c in found.index:\n",
    "        label = found_label.get(c, dict())\n",
    "        label[fr] = found.columns[((-1 < found.loc[c, :]) & \n",
    "                                   (found.loc[c, :] <= fr))].tolist()\n",
    "        found_label[c] = label\n",
    "found_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48848e3d-af1e-41fd-b065-65ba9cc2f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_client = dict()\n",
    "for fr in found_round:\n",
    "    found_client[fr] = found.index[((-1 < found.loc[:, :]) & \n",
    "                                    (found.loc[:, :] <= fr)).any(axis=1)].tolist()\n",
    "found_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b37c4-19b9-46bf-9632-fdc59c235633",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "target_size = (28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea2700-dd33-4383-98d3-24c0f424cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                       tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.Flatten(),\n",
    "                       tf.keras.layers.Dense(128, activation='relu'),\n",
    "                       tf.keras.layers.Dense(len(found_label['all'][0]))])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1da5f-420a-4305-ba3f-18ec8989e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_root, f'{0}', 'global')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51103daa-dd35-4106-8582-9556cd0208b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_round = 200\n",
    "cil_round = 10\n",
    "max_select = 5\n",
    "epochs = 10\n",
    "results = []\n",
    "for fr in range(max_round+1):\n",
    "    # Handle CIL\n",
    "    cil = 0\n",
    "    if fr in found_round:\n",
    "        round_client = found_client[fr]\n",
    "        round_label = found_label['all'][fr]\n",
    "        ### model\n",
    "        global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        new_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(round_label))])\n",
    "        new_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "        weights = model.get_weights()\n",
    "        diff = int(abs(weights[-1].shape[0]-len(found_label['all'][fr])))\n",
    "        if diff != 0:\n",
    "            weights[-2] = np.pad(weights[-2], (0, diff), mode='constant', constant_values=0)[:-diff,:]\n",
    "            weights[-1] = np.pad(weights[-1], (0, diff), mode='constant', constant_values=0)\n",
    "            for weight in weights[-2]:\n",
    "                for idx in range(-diff, 0):\n",
    "                    weight[idx] = random.uniform(-1, 1)\n",
    "        new_model.set_weights(weights)\n",
    "        for layer in new_model.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        new_model.save(model_path)\n",
    "        cil = cil_round\n",
    "        ### datasets\n",
    "        datasets = dict()\n",
    "        dataset_path = os.path.join(dataset_root, 'center', 'test')\n",
    "        datasets['all'] = image_generator.flow_from_directory(dataset_path, classes=round_label,\n",
    "                                                              target_size=target_size[:-1], shuffle=True,\n",
    "                                                              follow_links=True)\n",
    "        for client in round_client:\n",
    "            train_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'train')\n",
    "            test_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'test')\n",
    "            datasets[client] = (image_generator.flow_from_directory(train_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True),\n",
    "                                image_generator.flow_from_directory(test_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True))\n",
    "    if cil > 0:\n",
    "        cil = cil - 1\n",
    "    # Ready for global model and client model\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    knowledges = []\n",
    "    for client in round_client:\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        if cil == 0:\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = True\n",
    "        model.fit(datasets[client][0], \n",
    "                  # validation_data=datasets[client][1],\n",
    "                  epochs=epochs, verbose=0)\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model.save(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = copy.deepcopy(knowledges[0])\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    global_model = tf.keras.models.load_model(global_model_path)\n",
    "    global_model.set_weights(aggregates)\n",
    "    # Raw\n",
    "    confusions = dict()\n",
    "    for client in round_client:\n",
    "        actuals = datasets[client][1].classes\n",
    "        predictions = np.argmax(global_model.predict(datasets[client][1], verbose=0), axis=1)\n",
    "        confusions[client] = tf.math.confusion_matrix(actuals, predictions, len(round_label)).numpy()\n",
    "    # accuracy per each class\n",
    "    accuracies = dict()\n",
    "    for client in round_client:\n",
    "        acc = []\n",
    "        for l in range(len(round_label)):\n",
    "            sample_num = sum(confusions[client][l])\n",
    "            if sample_num != 0:\n",
    "                acc.append(confusions[client][l][l] / sample_num)\n",
    "            else:\n",
    "                acc.append(-1)\n",
    "        accuracies[client] = acc\n",
    "    # client per each class\n",
    "    parties = dict()\n",
    "    for client in round_client:\n",
    "        for l in range(len(round_label)):\n",
    "            if accuracies[client][l] != -1:\n",
    "                parties[l] = parties.get(l, 0) + 1\n",
    "    # raw effects by classes\n",
    "    effects_class = dict()\n",
    "    for l in range(len(round_label)):\n",
    "        acc_sum = 0\n",
    "        for client in round_client:\n",
    "            acc = accuracies[client][l]\n",
    "            if acc != -1:\n",
    "                acc_sum = acc_sum + acc\n",
    "        effect = dict()\n",
    "        for client in round_client:\n",
    "            acc = accuracies[client][l]\n",
    "            if acc != -1 and acc_sum != 0:\n",
    "                effect[client] = acc / acc_sum\n",
    "            elif acc == 0 and acc_sum == 0:\n",
    "                effect[client] = 1 / parties[l]\n",
    "            else:\n",
    "                effect[client] = -1\n",
    "        effects_class[l] = effect\n",
    "    # effects per clients\n",
    "    divs = dict()\n",
    "    for l in range(len(round_label)):\n",
    "        divs[l] = 1 / len(round_label)\n",
    "    effects = dict()\n",
    "    for key, value in effects_class.items():\n",
    "        for client, effect in value.items():\n",
    "            if effect != -1:\n",
    "                effects[client] = effects.get(client, 0) + effect*divs[key]\n",
    "    # selection with contribution\n",
    "    effect_list = list(effects.items())\n",
    "    effect_list.sort(key=operator.itemgetter(1), reverse=True)\n",
    "    knowledges = []\n",
    "    thres = (1/len(round_client))*0.8\n",
    "    selected = set()\n",
    "    for client, contrib in effect_list:\n",
    "        if contrib < thres:\n",
    "            continue\n",
    "        selected.add(client)\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = copy.deepcopy(knowledges[0])\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    model = tf.keras.models.load_model(global_model_path)\n",
    "    model.set_weights(aggregates)\n",
    "    result = model.evaluate(datasets['all'], verbose=0)\n",
    "    results.append(result)\n",
    "    print(f'Federated round: {fr+1}, Result: {result}, Selected: {selected} with {effect_list}')\n",
    "    global_model_path = os.path.join(model_root, f'{fr+1}', 'global')\n",
    "    model.save(global_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ee8e2-e095-490d-881d-5b06538b96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'result-fashionmnist-federatedlearning-oursthreshold-{today}.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLHub",
   "language": "python",
   "name": "flhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

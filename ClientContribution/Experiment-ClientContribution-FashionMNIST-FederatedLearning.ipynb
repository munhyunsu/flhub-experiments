{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775c37e9-c4b7-454c-bab4-3f8f27e666ce",
   "metadata": {},
   "source": [
    "# Experiment with Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368861b1-9d55-4d4b-9074-413502d09cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['AUTHGRAPH_VERBOSITY'] = '0'\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee385e86-0b5a-44e1-9e5d-0b08a1fffab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc179d44-fca3-4173-af47-f7dfa999e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnames = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db3049-7bbf-4e3c-b4c1-baf27aeae69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.abspath(os.path.expanduser('dataset-fashionmnist'))\n",
    "dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036b99f-b141-44cd-9bba-905778ccd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.abspath(os.path.expanduser('model-fashionmnist-force'))\n",
    "model_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac37a6-e010-4f73-8942-677868150a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = pd.read_csv('round-fashionmnist.csv', index_col='Clients')\n",
    "found.fillna(-1, inplace=True)\n",
    "found = found.astype('int')\n",
    "found.drop(columns=['Total'], inplace=True)\n",
    "found.drop(index=['Total'], inplace=True)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c098c5-f0f0-4fa3-9145-eeccbe9a6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_round = np.unique(found.values).tolist()\n",
    "found_round.remove(-1)\n",
    "found_round.sort(reverse=False)\n",
    "found_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd62b26b-6af5-4c7e-bf62-98938ff61945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "found_label = dict()\n",
    "for fr in found_round:\n",
    "    label = found_label.get('all', dict())\n",
    "    label[fr] = found.columns[((-1 < found.loc[:, :]) & \n",
    "                               (found.loc[:, :] <= fr)).any()].tolist()\n",
    "    found_label['all'] = label\n",
    "    for c in found.index:\n",
    "        label = found_label.get(c, dict())\n",
    "        label[fr] = found.columns[((-1 < found.loc[c, :]) & \n",
    "                                   (found.loc[c, :] <= fr))].tolist()\n",
    "        found_label[c] = label\n",
    "found_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bc24d-cca7-4a98-941f-4e0cc2aff963",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_client = dict()\n",
    "for fr in found_round:\n",
    "    found_client[fr] = found.index[((-1 < found.loc[:, :]) & \n",
    "                                    (found.loc[:, :] <= fr)).any(axis=1)].tolist()\n",
    "found_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109594e0-cab1-4d4e-acb8-0a40807ab0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "target_size = (28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c07e89-9293-45ec-8ad3-e4e24e0513c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                       tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.Flatten(),\n",
    "                       tf.keras.layers.Dense(128, activation='relu'),\n",
    "                       tf.keras.layers.Dense(len(found_label['all'][0]))])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888955b0-68b7-4bbc-a443-625424b0f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_root, f'{0}', 'global')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c189a-492a-47a9-a7d4-357157b5fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_round = 200\n",
    "cil_round = 20\n",
    "epochs = 10\n",
    "results = []\n",
    "for fr in range(max_round+1):\n",
    "    # Handle CIL\n",
    "    cil = 0\n",
    "    if fr in found_round:\n",
    "        round_client = found_client[fr]\n",
    "        round_label = found_label['all'][fr]\n",
    "        ### model\n",
    "        global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        new_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(round_label))])\n",
    "        new_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "        weights = model.get_weights()\n",
    "        diff = int(abs(weights[-1].shape[0]-len(found_label['all'][fr])))\n",
    "        if diff != 0:\n",
    "            weights[-2] = np.pad(weights[-2], (0, diff), mode='constant', constant_values=0)[:-diff,:]\n",
    "            weights[-1] = np.pad(weights[-1], (0, diff), mode='constant', constant_values=0)\n",
    "            for weight in weights[-2]:\n",
    "                for idx in range(-diff, 0):\n",
    "                    weight[idx] = random.uniform(-1, 1)\n",
    "        new_model.set_weights(weights)\n",
    "        for layer in new_model.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        new_model.save(model_path)\n",
    "        cil = cil_round\n",
    "        ### datasets\n",
    "        datasets = dict()\n",
    "        dataset_path = os.path.join(dataset_root, 'center', 'test')\n",
    "        datasets['all'] = image_generator.flow_from_directory(dataset_path, classes=round_label,\n",
    "                                                              target_size=target_size[:-1], shuffle=True,\n",
    "                                                              follow_links=True)\n",
    "        for client in round_client:\n",
    "            train_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'train')\n",
    "            test_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'test')\n",
    "            datasets[client] = (image_generator.flow_from_directory(train_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True),\n",
    "                                image_generator.flow_from_directory(test_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True))\n",
    "    if cil > 0:\n",
    "        cil = cil - 1\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    knowledges = []\n",
    "    for client in round_client:\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        if cil == 0:\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = False\n",
    "        model.fit(datasets[client][0], \n",
    "                  # validation_data=datasets[client][1],\n",
    "                  epochs=epochs, verbose=0)\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model.save(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = knowledges[0]\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    model = tf.keras.models.load_model(global_model_path)\n",
    "    model.set_weights(aggregates)\n",
    "    result = model.evaluate(datasets['all'], verbose=0)\n",
    "    results.append(result)\n",
    "    print(f'Federated round: {fr+1}, Result: {result}')\n",
    "    global_model_path = os.path.join(model_root, f'{fr+1}', 'global')\n",
    "    model.save(global_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67425632-41d2-4905-b238-c040a96530ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime('%y%m%d%H%M%S')\n",
    "with open(f'federated_learning_fashionmnist_force_{today}.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4f5d5-409d-40ad-9128-15f3180ab258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLHub",
   "language": "python",
   "name": "flhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

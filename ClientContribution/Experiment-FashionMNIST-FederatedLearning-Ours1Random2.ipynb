{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9e3105-ace4-4003-b9e0-317c411fa710",
   "metadata": {},
   "source": [
    "# Experiment with Fashion MNIST\n",
    "## Federated learning with ours 1 and random 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c74711-d52f-4823-883d-8c99ca293700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['AUTHGRAPH_VERBOSITY'] = '0'\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.random.set_seed(6292)\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4780935-e32d-4cf5-b9f1-bcabc7ac1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5463995a-a5a3-41ac-88b0-acce038ae946",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d2449-2d3c-4fde-b8bf-0fba7db297e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnames = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277eac2-d5b6-465d-add1-49c649d3c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.abspath(os.path.expanduser('dataset-fashionmnist'))\n",
    "dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5320477-e827-4a9e-a027-f0dd7421d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.abspath(os.path.expanduser(f'model-fashionmnist-ours1random2-{today}'))\n",
    "model_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dc8b5-a153-4e70-a1d6-de9f585f60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = pd.read_csv('round-fashionmnist.csv', index_col='Clients')\n",
    "found.fillna(-1, inplace=True)\n",
    "found = found.astype('int')\n",
    "found.drop(columns=['Total'], inplace=True)\n",
    "found.drop(index=['Total'], inplace=True)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d56866-b42a-4da4-a387-52c7ff54d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_round = np.unique(found.values).tolist()\n",
    "found_round.remove(-1)\n",
    "found_round.sort(reverse=False)\n",
    "found_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbff70b-1958-421c-ac15-819f03545195",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_label = dict()\n",
    "for fr in found_round:\n",
    "    label = found_label.get('all', dict())\n",
    "    label[fr] = found.columns[((-1 < found.loc[:, :]) & \n",
    "                               (found.loc[:, :] <= fr)).any()].tolist()\n",
    "    found_label['all'] = label\n",
    "    for c in found.index:\n",
    "        label = found_label.get(c, dict())\n",
    "        label[fr] = found.columns[((-1 < found.loc[c, :]) & \n",
    "                                   (found.loc[c, :] <= fr))].tolist()\n",
    "        found_label[c] = label\n",
    "found_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11ceee-e22f-4897-963f-1c7f4d7b61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_client = dict()\n",
    "for fr in found_round:\n",
    "    found_client[fr] = found.index[((-1 < found.loc[:, :]) & \n",
    "                                    (found.loc[:, :] <= fr)).any(axis=1)].tolist()\n",
    "found_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9474f2-b2bf-4cea-a345-ef538a18c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "target_size = (28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f352dc-7fac-43d5-b23f-e298cbbcb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                       tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.Flatten(),\n",
    "                       tf.keras.layers.Dense(128, activation='relu'),\n",
    "                       tf.keras.layers.Dense(len(found_label['all'][0]))])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d5a98-f6c2-4b21-8b09-615ad95f8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_root, f'{0}', 'global')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bfa4c-99ef-4234-8b98-73e7f54334e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_round = 200\n",
    "cil_round = 10\n",
    "max_select = 3\n",
    "contrib_select = 1\n",
    "epochs = 10\n",
    "results = []\n",
    "for fr in range(max_round+1):\n",
    "    # Handle CIL\n",
    "    cil = 0\n",
    "    if fr in found_round:\n",
    "        round_client = found_client[fr]\n",
    "        round_label = found_label['all'][fr]\n",
    "        ### model\n",
    "        global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        new_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(round_label))])\n",
    "        new_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "        weights = model.get_weights()\n",
    "        diff = int(abs(weights[-1].shape[0]-len(found_label['all'][fr])))\n",
    "        if diff != 0:\n",
    "            weights[-2] = np.pad(weights[-2], (0, diff), mode='constant', constant_values=0)[:-diff,:]\n",
    "            weights[-1] = np.pad(weights[-1], (0, diff), mode='constant', constant_values=0)\n",
    "            for weight in weights[-2]:\n",
    "                for idx in range(-diff, 0):\n",
    "                    weight[idx] = random.uniform(-1, 1)\n",
    "        new_model.set_weights(weights)\n",
    "        for layer in new_model.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        new_model.save(model_path)\n",
    "        cil = cil_round\n",
    "        ### datasets\n",
    "        datasets = dict()\n",
    "        dataset_path = os.path.join(dataset_root, 'center', 'test')\n",
    "        datasets['all'] = image_generator.flow_from_directory(dataset_path, classes=round_label,\n",
    "                                                              target_size=target_size[:-1], shuffle=True,\n",
    "                                                              follow_links=True)\n",
    "        for client in round_client:\n",
    "            train_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'train')\n",
    "            test_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'test')\n",
    "            datasets[client] = (image_generator.flow_from_directory(train_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True),\n",
    "                                image_generator.flow_from_directory(test_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True))\n",
    "    if cil > 0:\n",
    "        cil = cil - 1\n",
    "    # Ready for global model and client model\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    knowledges = []\n",
    "    for client in round_client:\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        if cil == 0:\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = False\n",
    "        model.fit(datasets[client][0], \n",
    "                  # validation_data=datasets[client][1],\n",
    "                  epochs=epochs, verbose=0)\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model.save(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = copy.deepcopy(knowledges[0])\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    global_model = tf.keras.models.load_model(global_model_path)\n",
    "    global_model.set_weights(aggregates)\n",
    "    # Raw\n",
    "    confusions = dict()\n",
    "    for client in round_client:\n",
    "        actuals = datasets[client][1].classes\n",
    "        predictions = np.argmax(global_model.predict(datasets[client][1], verbose=0), axis=1)\n",
    "        confusions[client] = tf.math.confusion_matrix(actuals, predictions, len(round_label)).numpy()\n",
    "    # accuracy per each class\n",
    "    accuracies = dict()\n",
    "    for client in round_client:\n",
    "        acc = []\n",
    "        for l in range(len(round_label)):\n",
    "            sample_num = sum(confusions[client][l])\n",
    "            if sample_num != 0:\n",
    "                acc.append(confusions[client][l][l] / sample_num)\n",
    "            else:\n",
    "                acc.append(-1)\n",
    "        accuracies[client] = acc\n",
    "    # client per each class\n",
    "    parties = dict()\n",
    "    for client in round_client:\n",
    "        for l in range(len(round_label)):\n",
    "            if accuracies[client][l] != -1:\n",
    "                parties[l] = parties.get(l, 0) + 1\n",
    "    # raw effects by classes\n",
    "    effects_class = dict()\n",
    "    for l in range(len(round_label)):\n",
    "        acc_sum = 0\n",
    "        for client in round_client:\n",
    "            acc = accuracies[client][l]\n",
    "            if acc != -1:\n",
    "                acc_sum = acc_sum + acc\n",
    "        effect = dict()\n",
    "        for client in round_client:\n",
    "            acc = accuracies[client][l]\n",
    "            if acc != -1 and acc_sum != 0:\n",
    "                effect[client] = acc / acc_sum\n",
    "            elif acc == 0 and acc_sum == 0:\n",
    "                effect[client] = 1 / parties[l]\n",
    "            else:\n",
    "                effect[client] = -1\n",
    "        effects_class[l] = effect\n",
    "    # effects per clients\n",
    "    divs = dict()\n",
    "    for l in range(len(round_label)):\n",
    "        divs[l] = 1 / len(round_label)\n",
    "    effects = dict()\n",
    "    for key, value in effects_class.items():\n",
    "        for client, effect in value.items():\n",
    "            if effect != -1:\n",
    "                effects[client] = effects.get(client, 0) + effect*divs[key]\n",
    "    # selection with contribution\n",
    "    effect_list = list(effects.items())\n",
    "    effect_list.sort(key=operator.itemgetter(1), reverse=True)\n",
    "    knowledges = []\n",
    "    client_bag = set()\n",
    "    selected = set()\n",
    "    for client in round_client:\n",
    "        client_bag.add(client)\n",
    "    for client, contrib in effect_list[:min(contrib_select, len(effect_list))]:\n",
    "        selected.add(client)\n",
    "        client_bag.remove(client)\n",
    "    for client in random.sample(list(client_bag), min(max_select-contrib_select, len(client_bag))):\n",
    "        selected.add(client)\n",
    "        client_bag.remove(client)\n",
    "    for client in selected:\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = copy.deepcopy(knowledges[0])\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    model = tf.keras.models.load_model(global_model_path)\n",
    "    model.set_weights(aggregates)\n",
    "    result = model.evaluate(datasets['all'], verbose=0)\n",
    "    results.append(result)\n",
    "    print(f'Federated round: {fr+1}, Result: {result}, Selected: {selected} with {effect_list}')\n",
    "    global_model_path = os.path.join(model_root, f'{fr+1}', 'global')\n",
    "    model.save(global_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLHub",
   "language": "python",
   "name": "flhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f5ea5f-a65f-4764-853a-cc0d04fd1cfc",
   "metadata": {},
   "source": [
    "# Experiment with Fashion MNIST\n",
    "## Federated learning with random selection 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6045d8-8f31-4ba3-a563-f461b3a50a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['AUTHGRAPH_VERBOSITY'] = '0'\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import operator\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.random.set_seed(6292)\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b6842-51d3-404e-a7d6-bdd2443cc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86dd3d2-468d-4f84-a9ad-6ee0efbe67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d8068-adbc-48d6-8503-37280affed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelnames = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b2eb7-6065-41ce-83c7-71e7d85b36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.abspath(os.path.expanduser('dataset-fashionmnist'))\n",
    "dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a5e16-79e4-4b06-a638-a74397eddea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = os.path.abspath(os.path.expanduser(f'model-fashionmnist-random3-{today}'))\n",
    "model_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8317b5-9726-4a10-b7b9-e4a963f5efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "found = pd.read_csv('round-fashionmnist.csv', index_col='Clients')\n",
    "found.fillna(-1, inplace=True)\n",
    "found = found.astype('int')\n",
    "found.drop(columns=['Total'], inplace=True)\n",
    "found.drop(index=['Total'], inplace=True)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300fcdb-e224-42de-a342-ade16537726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_round = np.unique(found.values).tolist()\n",
    "found_round.remove(-1)\n",
    "found_round.sort(reverse=False)\n",
    "found_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73375d7d-7441-4c4f-bd31-a00811d0c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_label = dict()\n",
    "for fr in found_round:\n",
    "    label = found_label.get('all', dict())\n",
    "    label[fr] = found.columns[((-1 < found.loc[:, :]) & \n",
    "                               (found.loc[:, :] <= fr)).any()].tolist()\n",
    "    found_label['all'] = label\n",
    "    for c in found.index:\n",
    "        label = found_label.get(c, dict())\n",
    "        label[fr] = found.columns[((-1 < found.loc[c, :]) & \n",
    "                                   (found.loc[c, :] <= fr))].tolist()\n",
    "        found_label[c] = label\n",
    "found_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840f459-558e-4b11-9d04-8c590ac75999",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_client = dict()\n",
    "for fr in found_round:\n",
    "    found_client[fr] = found.index[((-1 < found.loc[:, :]) & \n",
    "                                    (found.loc[:, :] <= fr)).any(axis=1)].tolist()\n",
    "found_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff424de3-4fc4-4b92-9f6e-658ef76a34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "target_size = (28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7476be9-7d99-438e-8730-6be2f179b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                       tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                       tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "                       tf.keras.layers.Flatten(),\n",
    "                       tf.keras.layers.Dense(128, activation='relu'),\n",
    "                       tf.keras.layers.Dense(len(found_label['all'][0]))])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e3ca4-2fba-46f2-a667-b9ad0a49978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_root, f'{0}', 'global')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ece0c7-ad19-47c4-acb4-fbbe7ce99cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_round = 200\n",
    "cil_round = 10\n",
    "max_select = 3\n",
    "epochs = 10\n",
    "results = []\n",
    "for fr in range(max_round+1):\n",
    "    # Handle CIL\n",
    "    cil = 0\n",
    "    if fr in found_round:\n",
    "        round_client = found_client[fr]\n",
    "        round_label = found_label['all'][fr]\n",
    "        ### model\n",
    "        global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        new_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=target_size),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(len(round_label))])\n",
    "        new_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])\n",
    "        weights = model.get_weights()\n",
    "        diff = int(abs(weights[-1].shape[0]-len(found_label['all'][fr])))\n",
    "        if diff != 0:\n",
    "            weights[-2] = np.pad(weights[-2], (0, diff), mode='constant', constant_values=0)[:-diff,:]\n",
    "            weights[-1] = np.pad(weights[-1], (0, diff), mode='constant', constant_values=0)\n",
    "            for weight in weights[-2]:\n",
    "                for idx in range(-diff, 0):\n",
    "                    weight[idx] = random.uniform(-1, 1)\n",
    "        new_model.set_weights(weights)\n",
    "        for layer in new_model.layers[:-2]:\n",
    "            layer.trainable = False\n",
    "        model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "        new_model.save(model_path)\n",
    "        cil = cil_round\n",
    "        ### datasets\n",
    "        datasets = dict()\n",
    "        dataset_path = os.path.join(dataset_root, 'center', 'test')\n",
    "        datasets['all'] = image_generator.flow_from_directory(dataset_path, classes=round_label,\n",
    "                                                              target_size=target_size[:-1], shuffle=True,\n",
    "                                                              follow_links=True)\n",
    "        for client in round_client:\n",
    "            train_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'train')\n",
    "            test_dataset_path = os.path.join(dataset_root, 'scenario', f'{client}', f'{fr}', 'test')\n",
    "            datasets[client] = (image_generator.flow_from_directory(train_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True),\n",
    "                                image_generator.flow_from_directory(test_dataset_path, classes=round_label,\n",
    "                                                                    target_size=target_size[:-1], shuffle=True,\n",
    "                                                                    follow_links=True))\n",
    "    if cil > 0:\n",
    "        cil = cil - 1\n",
    "    global_model_path = os.path.join(model_root, f'{fr}', 'global')\n",
    "    knowledges = []\n",
    "    selected = set()\n",
    "    for client in random.sample(round_client, min(max_select, len(round_client))):\n",
    "        selected.add(client)\n",
    "        model = tf.keras.models.load_model(global_model_path)\n",
    "        if cil == 0:\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = False\n",
    "        model.fit(datasets[client][0], \n",
    "                  # validation_data=datasets[client][1],\n",
    "                  epochs=epochs, verbose=0)\n",
    "        model_path = os.path.join(model_root, f'{fr}', f'{client}')\n",
    "        model.save(model_path)\n",
    "        knowledges.append(model.get_weights())\n",
    "    aggregates = copy.deepcopy(knowledges[0])\n",
    "    for knowledge in knowledges[1:]:\n",
    "        for i in range(len(knowledge)):\n",
    "            aggregates[i] = aggregates[i] + knowledge[i]\n",
    "    for i in range(len(aggregates)):\n",
    "        aggregates[i] = aggregates[i] / len(knowledges)\n",
    "    model = tf.keras.models.load_model(global_model_path)\n",
    "    model.set_weights(aggregates)\n",
    "    result = model.evaluate(datasets['all'], verbose=0)\n",
    "    results.append(result)\n",
    "    print(f'Federated round: {fr+1}, Result: {result}, Selected: {selected}')\n",
    "    global_model_path = os.path.join(model_root, f'{fr+1}', 'global')\n",
    "    model.save(global_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793ae03-1f67-4fab-9a9a-ca672960f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'result-fashionmnist-federatedlearning-random3-{today}.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLHub",
   "language": "python",
   "name": "flhub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
